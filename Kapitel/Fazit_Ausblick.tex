\section{Fazit und Ausblick}
\label{sec:fazit}

\subsection{Fazit}
Das Projektseminar Echtzeitsysteme 2018/2019 hat dem Team einen guten Einblick in die Problemlösung von echtzeitkritischen Aufgaben gegeben. 
Dabei hervorzuheben ist, dass die freie Gestaltung der Aufgabenstellung es ermöglicht hat, viele Lösungsmöglichkeiten auszuprobieren und kreativ zu sein. 
Die Herausforderung, auf einem ressourcenbeschränkten Roboterauto eine robuste, autonome Fahrassistenz zu betreiben, hat gezeigt, welche alltäglichen Probleme in der Industrie auftreten können. 
Bei allen Ideen zur Verbesserung von Prozessen muss daran gedacht werden, die eventuell auftretenden Zeitverzögerungen im System zu beachten.

Des Weiteren hat das Team einen tiefen Einblick sowohl in die unterschiedlichsten Methoden der Bildverarbeitung mittels OpenCV, als auch in die Regelung von autonomen Fahrzeugen und den Einsatz eines neuronalen Netzwerkes für die Schildererkennung erhalten. 
Die Arbeit mit dem Software-Framework ROS\cite{ROS} hat es ermöglicht, die Kommunikation zwischen den einzelnen Komponenten des Projekts gut zu strukturieren.

Durch Nutzung dieser Methoden und Technologien ist es uns zu Ende des Projekts gelungen,
eine funktionierende Linienerkennung, eine entsprechende Regelung
auf erkannte Linien zur autonomen Bewältigung des Rundkurses sowie eine Schildererkennung
mittels eines neuronalen Netzwerks zu implementieren.

\subsection{Probleme}
Während des Projekts sind einige Probleme wiederholt aufgetaucht. 
Das Häufigste war das Ausfallen der \textbf{\textit{uc\underline{\ }bridge}}, was die Arbeit mit dem Roboterauto oft schwer beeinträchtigt hat. 
Die Ultraschallsensoren, insbesondere der Vordere, waren oft stark verrauscht oder haben komplett ausgesetzt. 
Zuletzt haben der Antrieb und das Differential des vorderen linken Rades nicht mehr funktioniert, wodurch das Auto oft aus der Fahrbahn gezogen wurde.

Manchmal, wenn das Roboterauto mit einem Monitor verbunden werden sollte, hat der VGA-Anschluss des Autos kein Signal gesendet und man musste das Roboterauto manuell neu starten, um einen Monitor anschlie\ss{}en zu können. 

Die Lichtverhältnisse in den Räumen haben die Funktionalität der Bildverarbeitung au\ss erdem stark beeinträchtigt: 
Je nach Tageszeit hat das Testen zu unterschiedlichen Ergebnissen geführt. 
Das Team hat am Anfang des Projekts beschlossen, die bereitgestellte Webcam statt der Kinect zu nutzen, 
doch ohne eine feste Halterung hat sich die Kamera häufig verstellt und musste neu eingestellt werden. 
Eine vorgegebene Halterung wäre daher wünschenswert gewesen.

\subsection{Ausblick}
Obwohl die grundsätzlich angestrebte Funktionalität erreicht wurde, bieten einzelne
Aspekte des Projekts noch Raum für zukünftige Verbesserungen und Optimierungen.

Die Linienerkennung erfolgt zur Zeit über eine direkte Transformation des aufgenommenen
Webcam-Bilds in die Vogelperspektive, wobei alle weiteren Verarbeitungsschritte auf dem
transformierten Bild basieren.\\
Um sich den relativ zeitaufwendigen Schritt der perspektivischen Transformation zu sparen, könnte
in Zukunft eine Unterklasse von \texttt{LaneDetector} implementiert werden, die
nur einzelne Punkte transformiert und direkt auf dem Quellbild arbeitet. Die dafür
benötigten Transformationsmatrizen sind bereits vorhanden.
%TODO: Ausblick Regelung? Anderen Ansatz verwenden/testen? (Frederic)

Die Schildererkennung hat bereits sehr gute Ergebnisse geliefert, oft auf weite Entfernungen, doch das Roboterauto reagiert momentan noch nicht auf erkannte Schilder.
Ein Zustandsautomat zur Weiterverarbeitung der erkannten Objekte wurde bereits implementiert, dessen
Ausgabe-Messages müssten im nächsten Schritt jedoch noch von der Fahrzeugsteuerung
abonniert und weiterverwendet werden.